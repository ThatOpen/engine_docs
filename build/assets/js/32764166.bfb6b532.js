"use strict";(self.webpackChunkengine_docs=self.webpackChunkengine_docs||[]).push([[3866],{829:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>d});var r=t(4848),a=t(8453);const s={},o=void 0,i={id:"Tutorials/Fragments/Fragments/FragmentsModels/Materials",title:"Materials",description:'window.open("https://thatopen.github.io/engine_fragment/examples/FragmentsModels/Materials")} >Go Full Screen',source:"@site/docs/Tutorials/Fragments/Fragments/FragmentsModels/Materials.mdx",sourceDirName:"Tutorials/Fragments/Fragments/FragmentsModels",slug:"/Tutorials/Fragments/Fragments/FragmentsModels/Materials",permalink:"/Tutorials/Fragments/Fragments/FragmentsModels/Materials",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"EditProperties",permalink:"/Tutorials/Fragments/Fragments/FragmentsModels/EditProperties"},next:{title:"ModelInformation",permalink:"/Tutorials/Fragments/Fragments/FragmentsModels/ModelInformation"}},l={},d=[{value:"Working with Materials \ud83c\udfa8",id:"working-with-materials-",level:2},{value:"\ud83d\udd96 Importing our Libraries",id:"-importing-our-libraries",level:3},{value:"\ud83c\udf0e Setting up a Simple Scene",id:"-setting-up-a-simple-scene",level:3},{value:"\ud83c\udf05 Setting up HDRI Environment",id:"-setting-up-hdri-environment",level:3},{value:"\ud83d\udee0\ufe0f Setting Up Fragments",id:"\ufe0f-setting-up-fragments",level:3},{value:"\ud83d\uddbc\ufe0f Loading and Processing Textures",id:"\ufe0f-loading-and-processing-textures",level:3},{value:"\ud83c\udfa8 Material Processing and Enhancement",id:"-material-processing-and-enhancement",level:3},{value:"\ud83d\uddfa\ufe0f UV Mapping Generation",id:"\ufe0f-uv-mapping-generation",level:3},{value:"\ud83d\udcc2 Loading a Fragments Model",id:"-loading-a-fragments-model",level:3},{value:"\u270f\ufe0f Dynamic Material Editing",id:"\ufe0f-dynamic-material-editing",level:3},{value:"\ud83c\udf89 Congratulations!",id:"-congratulations",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",hr:"hr",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)("div",{style:{position:"relative"},children:[(0,r.jsx)("iframe",{src:"https://thatopen.github.io/engine_fragment/examples/FragmentsModels/Materials"}),(0,r.jsx)("button",{class:"full-screen-btn",onClick:()=>window.open("https://thatopen.github.io/engine_fragment/examples/FragmentsModels/Materials"),children:"Go Full Screen"})]}),"\n",(0,r.jsx)(n.admonition,{title:"Source",type:"info",children:(0,r.jsxs)(n.p,{children:["Copying and pasting? We've got you covered! You can find the full source code of this tutorial ",(0,r.jsx)(n.a,{href:"https://github.com/ThatOpen/engine_fragment/blob/main/packages/fragments/src/FragmentsModels/examples/Materials/example.ts",children:"here"}),"."]})}),"\n",(0,r.jsx)(n.h2,{id:"working-with-materials-",children:"Working with Materials \ud83c\udfa8"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.p,{children:"In this tutorial, we'll explore how to work with materials in Fragments models. We'll learn how to load textures, apply different material properties, and dynamically change materials on specific elements. Let's dive in!"}),"\n",(0,r.jsx)(n.h3,{id:"-importing-our-libraries",children:"\ud83d\udd96 Importing our Libraries"}),"\n",(0,r.jsx)(n.p,{children:"First things first, let's install all necessary dependencies to make this example work:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'import * as OBC from "@thatopen/components";\nimport * as THREE from "three";\nimport { RGBELoader } from "three/examples/jsm/loaders/RGBELoader.js";\nimport * as FRAGS from "../../../index";\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-setting-up-a-simple-scene",children:"\ud83c\udf0e Setting up a Simple Scene"}),"\n",(0,r.jsx)(n.p,{children:"To get started, let's set up a basic ThreeJS scene. This will serve as the foundation for our application and allow us to visualize the 3D models with proper lighting and shadows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const container = document.getElementById("container")!;\n\nconst components = new OBC.Components();\n\nconst worlds = components.get(OBC.Worlds);\n\nconst world = worlds.create<\n  OBC.ShadowedScene,\n  OBC.OrthoPerspectiveCamera,\n  OBC.SimpleRenderer\n>();\n\nworld.scene = new OBC.ShadowedScene(components);\nworld.renderer = new OBC.SimpleRenderer(components, container);\nworld.camera = new OBC.OrthoPerspectiveCamera(components);\n\ncomponents.init();\n\nconst axes = new THREE.AxesHelper(10);\nworld.scene.three.add(axes);\n\nworld.camera.controls.setLookAt(12, 6, 8, 0, 0, -10);\n\nworld.renderer.three.shadowMap.enabled = true;\nworld.renderer.three.shadowMap.type = THREE.PCFSoftShadowMap;\n\nworld.scene.setup({\n  directionalLight: {\n    color: new THREE.Color(1, 1, 1),\n    position: new THREE.Vector3(5, 10, 5),\n    intensity: 4,\n  },\n  shadows: {\n    cascade: 1,\n    resolution: 1024,\n  },\n});\n\nworld.renderer.three.toneMapping = THREE.NeutralToneMapping;\nworld.renderer.three.toneMappingExposure = 1;\n\nawait world.scene.updateShadows();\n\nworld.camera.controls.addEventListener("rest", async () => {\n  await world.scene.updateShadows();\n});\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-setting-up-hdri-environment",children:"\ud83c\udf05 Setting up HDRI Environment"}),"\n",(0,r.jsx)(n.p,{children:"We'll load an HDRI environment map to provide realistic lighting and reflections for our materials. This will make the materials look more realistic and help us see the effects of different material properties:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const hdriLoader = new RGBELoader();\nhdriLoader.load(\n  "https://thatopen.github.io/engine_fragment/resources/textures/envmaps/san_giuseppe_bridge_2k.hdr",\n  (texture) => {\n    texture.mapping = THREE.EquirectangularReflectionMapping;\n    // world.scene.three.background = texture;\n    world.scene.three.environment = texture;\n    // world.scene.three.environmentIntensity = 4;\n  },\n);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\ufe0f-setting-up-fragments",children:"\ud83d\udee0\ufe0f Setting Up Fragments"}),"\n",(0,r.jsx)(n.p,{children:"Now, let's configure the Fragments library core. This will allow us to load models effortlessly and start working with their materials:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'// prettier-ignore\nconst workerUrl = "https://thatopen.github.io/engine_fragment/resources/worker.mjs";\nconst fragments = new FRAGS.FragmentsModels(workerUrl);\nworld.camera.controls.addEventListener("control", () => fragments.update());\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\ufe0f-loading-and-processing-textures",children:"\ud83d\uddbc\ufe0f Loading and Processing Textures"}),"\n",(0,r.jsx)(n.p,{children:"We'll load various textures (color, normal, and roughness maps) that we'll use to create realistic materials. We'll also set up texture processing to ensure they wrap and repeat correctly:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const processTextures = (texture: THREE.Texture) => {\n  texture.wrapS = THREE.RepeatWrapping;\n  texture.wrapT = THREE.RepeatWrapping;\n  texture.repeat.set(0.1, 0.1);\n};\n\nconst textureLoader = new THREE.TextureLoader();\nconst colorTexture = textureLoader.load(\n  "https://thatopen.github.io/engine_fragment/resources/textures/concrete/Concrete012_2K-JPG_Color.jpg",\n);\ncolorTexture.colorSpace = THREE.SRGBColorSpace;\n\nprocessTextures(colorTexture);\n\nconst normalMap = textureLoader.load(\n  "https://thatopen.github.io/engine_fragment/resources/textures/concrete/Concrete012_2K-JPG_NormalGL.jpg",\n);\nprocessTextures(normalMap);\n\nconst roughnessMap = textureLoader.load(\n  "https://thatopen.github.io/engine_fragment/resources/textures/concrete/Concrete012_2K-JPG_Roughness.jpg",\n);\nprocessTextures(roughnessMap);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-material-processing-and-enhancement",children:"\ud83c\udfa8 Material Processing and Enhancement"}),"\n",(0,r.jsx)(n.p,{children:"We'll set up material processing to automatically enhance materials when they're loaded. This includes applying different material properties based on the material type and adding textures for more realistic appearance:"}),"\n",(0,r.jsx)(n.admonition,{title:"Material Types",type:"info",children:(0,r.jsx)(n.p,{children:"We'll identify different material types (like steel and concrete) based on their color properties and apply appropriate material settings for each type."})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'fragments.models.materials.list.onItemSet.add(\n  ({ key: id, value: material }) => {\n    if ("map" in material) {\n      // Steel material; we can also use material.localId to identify the material\n      if (\n        material.color.r === 1 &&\n        material.color.g === 0 &&\n        material.color.b === 0\n      ) {\n        const standardMaterial = new THREE.MeshStandardMaterial({\n          color: material.color,\n          metalness: 0.9,\n          roughnessMap,\n          roughness: 1,\n        }) as any;\n        fragments.models.materials.list.set(id, standardMaterial);\n        return;\n      }\n\n      // Concrete material\n      const standardMaterial = new THREE.MeshStandardMaterial({\n        color: material.color,\n        map: colorTexture,\n        normalMap,\n        roughnessMap,\n        roughness: 1,\n      }) as any;\n      fragments.models.materials.list.set(id, standardMaterial);\n    }\n  },\n);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\ufe0f-uv-mapping-generation",children:"\ud83d\uddfa\ufe0f UV Mapping Generation"}),"\n",(0,r.jsx)(n.p,{children:"We'll generate UV coordinates for the geometry to ensure textures are properly mapped. This is essential for displaying textures correctly on the 3D models:"}),"\n",(0,r.jsx)(n.admonition,{title:"UV Mapping",type:"warning",children:(0,r.jsx)(n.p,{children:"Without proper UV mapping, textures won't display correctly on the geometry. We'll use cubic projection to generate UV coordinates based on the geometry's normal vectors."})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'fragments.models.list.onItemSet.add(({ value: model }) => {\n  model.tiles.onItemSet.add(({ value: mesh }) => {\n    if (!("isLODGeometry" in mesh.geometry)) {\n      const geometry = mesh.geometry as THREE.BufferGeometry;\n\n      mesh.castShadow = true;\n      mesh.receiveShadow = true;\n\n      // Cubic UV projection\n\n      // Step 1: Determine the direction to use for projection\n\n      const indexArray = geometry.index!.array;\n      const positions = geometry.attributes.position!.array!;\n      const normals = geometry.attributes.normal!.array!;\n\n      const uvArray = new Float32Array((positions.length / 3) * 2);\n\n      for (let i = 0; i < indexArray.length; i++) {\n        const index = indexArray[i];\n        const x = positions[index * 3];\n        const y = positions[index * 3 + 1];\n        const z = positions[index * 3 + 2];\n\n        const nx1 = normals[index * 3];\n        const ny1 = normals[index * 3 + 1];\n        const nz1 = normals[index * 3 + 2];\n\n        const absNx = Math.abs(nx1);\n        const absNy = Math.abs(ny1);\n        const absNz = Math.abs(nz1);\n\n        if (absNx > absNy && absNx > absNz) {\n          // Use x direction\n          uvArray[index * 2] = y;\n          uvArray[index * 2 + 1] = z;\n        } else if (absNy > absNx && absNy > absNz) {\n          // Use y direction\n          uvArray[index * 2] = x;\n          uvArray[index * 2 + 1] = z;\n        } else {\n          // Use z direction\n          uvArray[index * 2] = x;\n          uvArray[index * 2 + 1] = y;\n        }\n      }\n\n      const attr = new THREE.BufferAttribute(uvArray, 2);\n      attr.onUpload(function callback(this: any) {\n        delete this.array;\n      });\n\n      geometry.setAttribute("uv", attr);\n    }\n  });\n});\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-loading-a-fragments-model",children:"\ud83d\udcc2 Loading a Fragments Model"}),"\n",(0,r.jsx)(n.p,{children:"With the core setup complete, it's time to load a Fragments model into our scene. This model will serve as our test subject for material operations:"}),"\n",(0,r.jsx)(n.admonition,{title:"Where can I find Fragment files?",type:"info",children:(0,r.jsx)(n.p,{children:"You can use the sample Fragment files available in our repository for testing. If you have an IFC model you'd like to convert to Fragments, check out the IfcImporter tutorial for detailed instructions."})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const fetched = await fetch(\n  "https://thatopen.github.io/engine_fragment/resources/frags/school_str.frag",\n);\nconst buffer = await fetched.arrayBuffer();\n\nconst model = await fragments.load(buffer, {\n  modelId: "test",\n  camera: world.camera.three,\n});\nworld.scene.three.add(model.object);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\ufe0f-dynamic-material-editing",children:"\u270f\ufe0f Dynamic Material Editing"}),"\n",(0,r.jsx)(n.p,{children:"Now we'll demonstrate how to dynamically change materials on specific elements. We'll identify steel elements and apply a new red material to them, showing how to programmatically modify materials in a Fragments model:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const elements = await model.getItemsOfCategories([\n  /IFCCOLUMN/,\n  /IFCBEAM/,\n  /IFCMEMBER/,\n]);\nconst elementsIds = Object.values(elements).flat();\n\nconst steelElementsIds = new Set<number>();\nfor (const element of elementsIds) {\n  const data = await model.getItemsData([element], {\n    attributes: ["Name", "NominalValue"],\n    relations: {\n      IsDefinedBy: { attributes: true, relations: true },\n      DefinesOcurrence: { attributes: false, relations: false },\n    },\n  });\n  const objectType = data[0].ObjectType as FRAGS.ItemAttribute;\n  if (!objectType.value.includes("Concrete")) {\n    steelElementsIds.add(element);\n  }\n}\n\nconst requests: FRAGS.EditRequest[] = [];\n\nconst newMaterial = {\n  r: 255,\n  g: 0,\n  b: 0,\n  a: 255,\n  renderedFaces: 0,\n  stroke: 0,\n};\n\nrequests.push({\n  type: FRAGS.EditRequestType.CREATE_MATERIAL,\n  tempId: "new-material",\n  data: newMaterial,\n});\n\nconst globalTransformIds = new Set(\n  await model.getGlobalTranformsIdsOfItems(Array.from(steelElementsIds)),\n);\n\nconst samples = await model.getSamples();\nfor (const [localId, sample] of samples) {\n  if (globalTransformIds.has(sample.item)) {\n    requests.push({\n      type: FRAGS.EditRequestType.UPDATE_SAMPLE,\n      localId,\n      data: { ...sample, material: "new-material" },\n    });\n  }\n}\n\nawait fragments.editor.edit(model.modelId, requests);\nawait fragments.update(true);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-congratulations",children:"\ud83c\udf89 Congratulations!"}),"\n",(0,r.jsx)(n.p,{children:"You've successfully learned how to work with materials in Fragments models! \ud83d\ude80\nNow you can load textures, apply different material properties, and dynamically change materials on specific elements. Ready to explore more? Check out our other tutorials to unlock the full potential of Fragments! \ud83d\udca1"})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var r=t(6540);const a={},s=r.createContext(a);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);